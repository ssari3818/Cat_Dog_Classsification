# -*- coding: utf-8 -*-
"""CNN_Project_Image_Classification_with_CNN_(catdogclassifier)_Student.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f4zarxKf08fM-iHSr5eG1OqZf4Fhtpbk

<p style="text-align: center;"><img src="https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV" class="img-fluid" alt="Rossum"></p>

<h1 style="text-align: center;">Deep Learning<br><br>Image Classification with CNN<br><br>Cat-Dog Classification Project<br><h1>

# Dataset Info

The Dogs vs. Cats dataset is a common computer vision dataset in which pictures are classified as either including a dog or a cat.

After the dataset is well studied, it can be used to understand and practice how to design, evaluate, and apply convolutional neural networks for image classification.

You will build a classifier with images and try to detect dogs versus cats using CNN.

Train set includes 12500 cat-5026 dog images, validation set includes 1219 cat-1071 dog images and test set incgludes 6897 cat and dogs images together.

# Import Libraries and Export Images from Zip_File
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.image import imread

#import warnings
#warnings.filterwarnings("ignore")
#warnings.warn("this will not show")

plt.rcParams["figure.figsize"] = (10,6)

sns.set_style("whitegrid")
pd.set_option('display.float_format', lambda x: '%.3f' % x)

# Set it None to display all rows in the dataframe
# pd.set_option('display.max_rows', None)

# Set it to None to display all columns in the dataframe
pd.set_option('display.max_columns', None)

import tensorflow as tf

tf.config.list_physical_devices("GPU")

from google.colab import drive
drive.mount('/content/drive/')

import zipfile

# Unzip the file
zip_ref = zipfile.ZipFile("/content/drive/MyDrive/cat_dog_data.zip", "r")
zip_ref.extractall()
zip_ref.close()

"""# Recognizing and Understanding Data"""

my_data_dir = "data"

test_path = my_data_dir + '/test/'
train_path = my_data_dir + '/train/'
valid_path = my_data_dir + '/validation/'

os.listdir(test_path)[3]

os.listdir(my_data_dir)

os.listdir(valid_path)

classes = os.listdir(train_path)
classes

import pathlib

data_dir = pathlib.Path(train_path) # turn our training path into a Python path
class_names = np.array(sorted([item.name for item in data_dir.glob('*')])) # created a list of class_names from the subdirectories
print(class_names)

class_names

os.listdir(valid_path)

data_dir = pathlib.Path(valid_path) # turn our training path into a Python path
class_names = np.array(sorted([item.name for item in data_dir.glob('*')])) # created a list of class_names from the subdirectories
print(class_names)

"""**Let's check how many images there are.**"""

os.listdir(train_path+'cat')

len(os.listdir(train_path+'cat')), len(os.listdir(train_path+'dog'))

len(os.listdir(valid_path+'cat')), len(os.listdir(valid_path+'dog'))

for dirpath, dirnames, filenames in os.walk(my_data_dir):
  print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")

"""**Let's take an example images from both train-cat and train-dog folders to observe process** """

os.listdir(train_path+'cat')[:10]

os.listdir(train_path+'cat')[5]

cat_path = train_path+'cat'+'/cat.931.jpg'

cat_path

imread(cat_path)

cat_ce = imread(cat_path)

plt.imshow(cat_ce);

cat_ce.shape

os.listdir(train_path+'dog')[:10]

dog_path = train_path+'dog/'+os.listdir(train_path+'dog')[5]

imread(dog_path)

dog_ce = imread(dog_path)
plt.imshow(dog_ce);

dog_ce.shape

# View a random image
import random
def view_random_image(target_dir, target_class):
  # Setup target directory (we'll view images from here)
  target_folder = target_dir+target_class

  # Get a random image path
  random_image = random.sample(os.listdir(target_folder), 1)

  # Read in the image and plot it using matplotlib
  img = imread(target_folder + "/" + random_image[0])
  plt.imshow(img)
  plt.title(target_class)
  plt.axis("off");

  print(f"Image shape: {img.shape}") # show the shape of the image

  return img

# View a random image from the training dataset
img = view_random_image(target_dir=train_path,
                        target_class="cat")

# View a random image from the training dataset
img = view_random_image(target_dir=train_path,
                        target_class="dog")

# View a random image from the training dataset
import random
img = view_random_image(target_dir=train_path,
                        target_class=random.choice(class_names)) # get a random class name

"""# Data Preprocessing

## Defining Input Shape

**Let's decide on the final dimension of these images.**
"""

dog_ce.shape

cat_ce.shape

x = [imread(train_path+'dog/'+image).shape[0] for image in os.listdir(train_path+'dog') if 'Thumbs.db' not in image]
y = [imread(train_path+'dog/'+image).shape[1] for image in os.listdir(train_path+'dog') if 'Thumbs.db' not in image]

x[:5]

sns.scatterplot(x,y);

np.mean(x), np.median(x)

np.mean(y), np.median(y)

image_shape = (360,300,3)

"""## Scalling

**Let's check the images if they are needed to be scaled or not**
"""

dog_ce.max()

cat_ce.max()

dog_ce= dog_ce.astype('float32')
cat_ce = cat_ce.astype('float32')
dog_ce/= 255
cat_ce /= 255

dog_ce.max()

cat_ce.max()

dog_ce.min()

cat_ce.min()

"""## Image Data Generator

**Image Manipulation**

We can use the ImageDataGenerator to manipulate the images with rotation, resizing, and scaling so the model becomes more robust to different images that our data set doesn't have. ImageDataGenerator does the followings.

* Accepts a batch of images used for training.
* Applies a series of random transformations to each image in the batch.
* Replaces the original batch with randomly transformed batch.
* Training the CNN on this randomly transformed batch.

The goal of applying data augmentation is to have a more generalized model.

Data augmentation is a way to try and prevent a model overfitting. If your model is overfiting (e.g. the validation loss keeps increasing), you may want to try using data augmentation.
"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

image_gen = ImageDataGenerator(rotation_range=15, 
                               width_shift_range=0.10, 
                               height_shift_range=0.10, 
                               #rescale=1/255, 
                               shear_range=0.1, 
                               zoom_range=0.1, 
                               horizontal_flip=True, 
                               fill_mode='nearest')

plt.imshow(cat_ce);

plt.imshow(image_gen.random_transform(cat_ce));



"""### Taking the path to a directory & Generating batches of augmented data

flow_from_directory function works with images organized in sub-directories. Your directories should include only one class of images, so one folder per class of images.
"""

image_gen.flow_from_directory(train_path)

image_gen.flow_from_directory(valid_path)

batch_size = 32

image_shape

train_image_gen = image_gen.flow_from_directory(directory=train_path,
                                                target_size=image_shape[:2],
                                                color_mode='rgb',
                                                batch_size=batch_size,
                                                class_mode='binary',
                                                shuffle=True)

valid_image_gen = image_gen.flow_from_directory(directory=valid_path,
                                               target_size=image_shape[:2],
                                               color_mode='rgb',
                                               batch_size=batch_size,
                                               class_mode='binary',
                                               shuffle=False)

train_image_gen.class_indices

valid_image_gen.class_indices

train_image_gen[0]

train_image_gen[0][0].shape

train_image_gen[0][0][0].shape

len(train_image_gen), len(valid_image_gen)

len(train_image_gen)*batch_size, len(valid_image_gen)*batch_size

images, labels = train_image_gen.next() # get the 'next' batch of images/labels
len(images), len(labels)

images, labels = valid_image_gen.next() # get the 'next' batch of images/labels
len(images), len(labels)

"""# Modelling"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import BatchNormalization

from sklearn.metrics import classification_report, confusion_matrix

model2 = Sequential()

model2.add(Conv2D(filters=32, kernel_size=(3,3),input_shape=image_shape, padding='same', activation='relu',))
model2.add(MaxPooling2D(pool_size=(2, 2)))

model2.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))
model2.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))
model2.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))
model2.add(BatchNormalization())
model2.add(MaxPooling2D(pool_size=(2, 2)))

model2.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))
model2.add(BatchNormalization())
model2.add(MaxPooling2D(pool_size=(2, 2)))

model2.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))
model2.add(BatchNormalization())
model2.add(MaxPooling2D(pool_size=(2, 2)))


model2.add(Flatten())


model2.add(Dense(128))
model2.add(BatchNormalization())
model2.add(Activation('relu'))
model2.add(Dropout(0.5))

model2.add(Dense(1))
model2.add(Activation('sigmoid'))

model2.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

model2.summary()

early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights = True)

model2.fit(train_image_gen,
          epochs=12,
          steps_per_epoch=len(train_image_gen),
          validation_data= valid_image_gen,
          validation_steps=len(valid_image_gen),
          callbacks=[early_stop])

model2.metrics_names

summary = pd.DataFrame(model2.history.history)
summary.tail()

summary[["loss", "val_loss"]].plot();

summary[["accuracy", "val_accuracy"]].plot();

"""Evaluation on test data"""

score = model2.evaluate(valid_image_gen)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

pred_prob = model2.predict(valid_image_gen)

y_pred = pred_prob > 0.5

y_test = valid_image_gen.classes
y_test

from sklearn.metrics import classification_report, confusion_matrix

print(classification_report(y_test, y_pred))

confusion_matrix(y_test, y_pred)

model2.save('cat_dog_model_2.h5')

"""# Prediction"""

from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image

model=load_model('cat_dog_model_2.h5')

target_class=random.choice(class_names)
target_class

cwd = os.getcwd()  # Get the current working directory (cwd)
files = os.listdir(cwd)  # Get all the files in that directory
print("Files in %r: %s" % (cwd, files))

random_image = random.sample(os.listdir(valid_path + target_class), 1)
random_image

image_path = valid_path + target_class + "/" + random_image[0]
image_path

my_image = image.load_img(image_path, target_size=image_shape)

my_image

type(my_image)

my_image = image.img_to_array(my_image)

my_image.shape

my_image = np.expand_dims(my_image, axis=0)

my_image.shape

model.predict(my_image)

train_image_gen.class_indices

"""# test predict"""

random_image1 = os.listdir(test_path)[26]
random_image1

image_path1 = my_data_dir + '/test/'+ random_image1
image_path1

my_image1 = image.load_img(image_path1, target_size=image_shape)

my_image1

type(my_image1)

my_image1 = image.img_to_array(my_image1)

my_image1.shape

my_image1 = np.expand_dims(my_image1, axis=0)

my_image1.shape

model.predict(my_image1)

train_image_gen.class_indices

"""___

<p style="text-align: center;"><img src="https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV" class="img-fluid" alt="CLRSWY"></p>

___
"""